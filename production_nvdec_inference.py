#!/usr/bin/env python3
"""
Production NVDEC Inference Pipeline
High-performance HEVC-compatible video processing with NVDEC GPU decoding
- NVDEC Raw: 543+ FPS (21x real-time)
- HEVC compatible (unlike DALI)
- Optimized for RTX 4090 with TensorRT
"""

import time
import argparse
import csv
import numpy as np
import os
import threading
import queue
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
import subprocess
import tempfile
import cv2

# TensorRT imports
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import torch
import torchvision.ops as ops

TRT_LOGGER = trt.Logger(trt.Logger.WARNING)


class NVDECVideoDecoder:
    """High-performance NVDEC video decoder with batch processing"""
    
    def __init__(self, video_path, batch_size=16, target_size=(960, 960)):
        self.video_path = Path(video_path)
        self.batch_size = batch_size
        self.target_size = target_size
        
        if not self.video_path.exists():
            raise FileNotFoundError(f"Video file not found: {video_path}")
        
        print(f"üé¨ NVDEC Decoder initialized")
        print(f"   Video: {self.video_path.name}")
        print(f"   Batch size: {batch_size}")
        print(f"   Target size: {target_size}")
        
        # Get video information
        self.video_info = self._get_video_info()
        print(f"   Video info: {self.video_info['width']}x{self.video_info['height']}, "
              f"{self.video_info['fps']:.1f} FPS, {self.video_info['total_frames']} frames")
    
    def _get_video_info(self):
        """Get video information using ffprobe"""
        cmd = [
            'ffprobe', '-v', 'quiet', '-print_format', 'json',
            '-show_format', '-show_streams', str(self.video_path)
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            import json
            info = json.loads(result.stdout)
            
            for stream in info['streams']:
                if stream['codec_type'] == 'video':
                    fps = eval(stream['r_frame_rate'])
                    
                    # Try to get duration from stream or format
                    duration = 0
                    if 'duration' in stream:
                        duration = float(stream['duration'])
                    elif 'duration' in info.get('format', {}):
                        duration = float(info['format']['duration'])
                    
                    total_frames = int(fps * duration) if duration > 0 else 0
                    
                    return {
                        'fps': fps,
                        'duration': duration,
                        'total_frames': total_frames,
                        'codec': stream['codec_name'],
                        'width': stream['width'],
                        'height': stream['height']
                    }
        except Exception as e:
            print(f"Warning: Could not get video info: {e}")
            return {'fps': 25, 'duration': 0, 'total_frames': 0, 'codec': 'unknown', 'width': 1920, 'height': 1080}
    
    def decode_batch_generator(self, frame_skip=25, max_frames=None):
        """Generate batches of decoded frames using NVDEC"""
        frame_count = 0
        current_batch = []
        current_indices = []
        
        # Calculate total frames to process
        total_frames = self.video_info.get('total_frames', 0)
        if total_frames == 0:
            total_frames = max_frames if max_frames else 1000  # Default estimate
        
        total_to_process = min(max_frames, total_frames) if max_frames else total_frames
        frames_to_process = total_to_process // frame_skip if frame_skip > 1 else total_to_process
        
        print(f"üöÄ Starting NVDEC batch decoding")
        print(f"   Frame skip: {frame_skip}")
        print(f"   Frames to process: {frames_to_process}")
        
        # Use ffmpeg with NVDEC to decode video
        cmd = [
            'ffmpeg', '-y',
            '-hwaccel', 'nvdec',
            '-c:v', 'hevc',
            '-i', str(self.video_path),
            '-vf', f'select=not(mod(n\\,{frame_skip})),scale={self.target_size[0]}:{self.target_size[1]}',
            '-pix_fmt', 'rgb24',
            '-f', 'rawvideo',
            '-'
        ]
        
        if max_frames:
            # Calculate actual frames after skipping
            max_output_frames = max_frames // frame_skip
            # Insert before the '-f' argument
            cmd.insert(-3, '-frames:v')
            cmd.insert(-3, str(max_output_frames))
        
        try:
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            frame_size = self.target_size[0] * self.target_size[1] * 3  # RGB24
            
            while True:
                # Read frame data
                frame_data = process.stdout.read(frame_size)
                
                if len(frame_data) != frame_size:
                    break
                
                # Convert to numpy array and reshape
                frame = np.frombuffer(frame_data, dtype=np.uint8)
                frame = frame.reshape((self.target_size[1], self.target_size[0], 3))
                
                # Convert RGB to BGR for OpenCV compatibility
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                
                current_batch.append(frame)
                current_indices.append(frame_count * frame_skip)
                
                # Yield batch when full
                if len(current_batch) == self.batch_size:
                    yield np.array(current_batch), current_indices
                    current_batch = []
                    current_indices = []
                
                frame_count += 1
                
                if frame_count % 100 == 0:
                    print(f"   üìä Decoded {frame_count} frames")
            
            # Yield remaining frames
            if current_batch:
                yield np.array(current_batch), current_indices
            
            # Wait for process to complete
            process.wait()
            
            if process.returncode != 0:
                stderr_output = process.stderr.read().decode()
                print(f"   ‚ö†Ô∏è NVDEC process warning: {stderr_output}")
            
            print(f"   ‚úÖ NVDEC decoding complete: {frame_count} frames processed")
            
        except Exception as e:
            print(f"   ‚ùå NVDEC decoding failed: {e}")
            if 'process' in locals():
                process.terminate()


class NVDECTensorRTProcessor:
    """TensorRT inference processor optimized for NVDEC input"""
    
    def __init__(self, engine_path, batch_size=16):
        self.batch_size = batch_size
        self.device = torch.device('cuda:0')
        
        print(f"üöÄ Initializing NVDEC-TensorRT Processor")
        print(f"   Engine: {engine_path}")
        print(f"   Batch size: {batch_size}")
        
        # Load TensorRT engine
        with open(engine_path, 'rb') as f:
            runtime = trt.Runtime(TRT_LOGGER)
            self.engine = runtime.deserialize_cuda_engine(f.read())
        
        self.context = self.engine.create_execution_context()
        self.stream = cuda.Stream()
        
        # Get tensor information
        self.input_name = None
        self.output_names = []
        
        for i in range(self.engine.num_io_tensors):
            tensor_name = self.engine.get_tensor_name(i)
            is_input = self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT
            
            if is_input:
                self.input_name = tensor_name
            else:
                self.output_names.append(tensor_name)
        
        # Pre-allocate memory
        self._allocate_memory()
        
        # Performance tracking
        self.processed_frames = 0
        self.total_detections = 0
        self.inference_times = []
        self.start_time = None
        
        print(f"   ‚úÖ TensorRT processor ready")
    
    def _allocate_memory(self):
        """Pre-allocate GPU memory for inference"""
        # Input memory
        input_shape = (self.batch_size, 3, 960, 960)
        input_size = int(np.prod(input_shape) * 4)
        
        self.d_input = cuda.mem_alloc(input_size)
        self.h_input = cuda.pagelocked_empty(input_shape, dtype=np.float32)
        
        # Output memory
        self.output_allocations = []
        
        # Set input shape to get output shapes
        self.context.set_input_shape(self.input_name, input_shape)
        
        for output_name in self.output_names:
            try:
                output_shape = self.context.get_tensor_shape(output_name)
                shape_tuple = tuple(output_shape[i] for i in range(len(output_shape)))
                
                output_size = int(np.prod(shape_tuple) * 4)
                d_output = cuda.mem_alloc(output_size)
                h_output = cuda.pagelocked_empty(shape_tuple, dtype=np.float32)
                
                self.output_allocations.append({
                    'name': output_name,
                    'device': d_output,
                    'host': h_output,
                    'shape': shape_tuple
                })
                
            except Exception as e:
                print(f"   Warning: Could not allocate for {output_name}: {e}")
        
        total_memory = (input_size + sum(np.prod(out['shape']) * 4 for out in self.output_allocations)) / (1024**2)
        print(f"   üíæ GPU memory allocated: {total_memory:.1f} MB")
    
    def process_video_nvdec(self, video_path, output_csv, frame_skip=25, max_frames=None):
        """Process video using NVDEC decoding + TensorRT inference"""
        print(f"\nüé¨ Processing Video with NVDEC + TensorRT")
        print(f"   Video: {video_path}")
        print(f"   Output: {output_csv}")
        print(f"   Frame skip: {frame_skip}")
        
        self.start_time = time.time()
        
        # Initialize NVDEC decoder
        decoder = NVDECVideoDecoder(video_path, self.batch_size)
        
        # Results storage
        results_list = []
        
        try:
            # Process batches from NVDEC
            batch_count = 0
            for batch_frames, frame_indices in decoder.decode_batch_generator(frame_skip, max_frames):
                if len(batch_frames) == 0:
                    continue
                
                # Process batch with TensorRT
                detections = self._process_batch(batch_frames, frame_indices)
                results_list.extend(detections)
                
                batch_count += 1
                
                # Progress update
                if batch_count % 10 == 0:
                    self._print_progress()
        
        except KeyboardInterrupt:
            print(f"\n‚ö†Ô∏è Processing interrupted by user")
        except Exception as e:
            print(f"\n‚ùå Error during processing: {e}")
            import traceback
            traceback.print_exc()
        
        # Save results
        if results_list:
            self._save_results(results_list, output_csv)
        
        # Print final statistics
        self._print_final_stats()
        
        return results_list
    
    def _process_batch(self, batch_frames, frame_indices):
        """Process batch with TensorRT inference"""
        batch_start = time.time()
        
        # Preprocess frames for TensorRT
        actual_batch_size = len(batch_frames)
        for i, frame in enumerate(batch_frames):
            # Normalize and transpose
            frame_norm = frame.astype(np.float32) / 255.0
            frame_chw = np.transpose(frame_norm, (2, 0, 1))  # HWC to CHW
            self.h_input[i] = frame_chw
        
        # Set dynamic shape
        input_shape = (actual_batch_size, 3, 960, 960)
        self.context.set_input_shape(self.input_name, input_shape)
        
        # Copy to GPU and run inference
        cuda.memcpy_htod_async(self.d_input, self.h_input[:actual_batch_size], self.stream)
        
        # Set tensor addresses
        self.context.set_tensor_address(self.input_name, int(self.d_input))
        for output_alloc in self.output_allocations:
            self.context.set_tensor_address(output_alloc['name'], int(output_alloc['device']))
        
        # Execute inference
        try:
            success = self.context.execute_async_v3(self.stream.handle)
            
            if not success:
                print(f"   ‚ö†Ô∏è TensorRT inference failed for batch")
                return []
            
            self.stream.synchronize()
        except Exception as e:
            print(f"   ‚ö†Ô∏è TensorRT execution error: {e}")
            return []
        
        # Get results
        main_output = max(self.output_allocations, key=lambda x: np.prod(x['shape']))
        cuda.memcpy_dtoh(main_output['host'][:actual_batch_size], main_output['device'])
        
        # Track performance
        inference_time = (time.time() - batch_start) * 1000
        self.inference_times.append(inference_time)
        
        # Process detections with GPU NMS
        predictions = main_output['host'][:actual_batch_size]
        batch_detections = self._gpu_nms_batch(predictions)
        
        # Convert to results format
        results = []
        for frame_idx, detections in zip(frame_indices, batch_detections):
            if detections is not None:
                boxes, scores, classes = detections
                for j in range(len(boxes)):
                    results.append({
                        'frame': frame_idx,
                        'class': int(classes[j]),
                        'confidence': float(scores[j]),
                        'xmin': float(boxes[j][0]),
                        'ymin': float(boxes[j][1]),
                        'xmax': float(boxes[j][2]),
                        'ymax': float(boxes[j][3])
                    })
                
                self.total_detections += len(boxes)
        
        self.processed_frames += actual_batch_size
        return results
    
    def _gpu_nms_batch(self, predictions, conf_threshold=0.25, nms_threshold=0.45):
        """GPU-accelerated NMS for batch predictions"""
        batch_results = []
        
        for pred in predictions:
            try:
                if pred is None or pred.size == 0:
                    batch_results.append(None)
                    continue
                
                # Convert to torch tensor on GPU
                pred_tensor = torch.from_numpy(pred).to(self.device)
                
                # Handle different output formats
                if pred_tensor.dim() == 1:
                    if pred_tensor.numel() % 7 == 0:
                        pred_tensor = pred_tensor.view(-1, 7)
                    else:
                        batch_results.append(None)
                        continue
                elif pred_tensor.dim() == 2 and pred_tensor.shape[0] == 7:
                    pred_tensor = pred_tensor.transpose(0, 1)
                
                if pred_tensor.shape[-1] < 5:
                    batch_results.append(None)
                    continue
                
                # Extract components
                boxes = pred_tensor[:, :4]
                confidence = pred_tensor[:, 4]
                
                # Filter by confidence
                conf_mask = confidence > conf_threshold
                if not conf_mask.any():
                    batch_results.append(None)
                    continue
                
                boxes = boxes[conf_mask]
                confidence = confidence[conf_mask]
                
                # Convert to corner format for NMS
                x_center, y_center, width, height = boxes.unbind(1)
                x1 = x_center - width * 0.5
                y1 = y_center - height * 0.5
                x2 = x_center + width * 0.5
                y2 = y_center + height * 0.5
                corner_boxes = torch.stack([x1, y1, x2, y2], dim=1)
                
                # Get classes
                if pred_tensor.shape[-1] > 5:
                    class_scores = pred_tensor[conf_mask, 5:]
                    class_ids = torch.argmax(class_scores, dim=1)
                else:
                    class_ids = torch.zeros(len(boxes), dtype=torch.long, device=self.device)
                
                # Apply GPU NMS
                if len(corner_boxes) > 0:
                    keep_indices = ops.nms(corner_boxes, confidence, nms_threshold)
                    
                    final_boxes = corner_boxes[keep_indices]
                    final_scores = confidence[keep_indices]
                    final_classes = class_ids[keep_indices]
                    
                    batch_results.append((final_boxes.cpu().numpy(), 
                                        final_scores.cpu().numpy(), 
                                        final_classes.cpu().numpy()))
                else:
                    batch_results.append(None)
                    
            except Exception as e:
                batch_results.append(None)
        
        return batch_results
    
    def _save_results(self, results, output_path):
        """Save detection results to CSV"""
        print(f"\nüíæ Saving results to: {output_path}")
        
        with open(output_path, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['frame', 'class', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax'])
            
            for result in results:
                writer.writerow([
                    result['frame'],
                    result['class'],
                    result['confidence'],
                    result['xmin'],
                    result['ymin'],
                    result['xmax'],
                    result['ymax']
                ])
        
        print(f"   ‚úÖ Saved {len(results)} detections")
    
    def _print_progress(self):
        """Print progress update"""
        if self.start_time:
            elapsed = time.time() - self.start_time
            fps = self.processed_frames / elapsed if elapsed > 0 else 0
            avg_inference = np.mean(self.inference_times[-50:]) if self.inference_times else 0
            
            print(f"   üìä Progress: {self.processed_frames} frames, "
                  f"{fps:.1f} FPS, {avg_inference:.1f}ms/batch, "
                  f"{self.total_detections} detections")
    
    def _print_final_stats(self):
        """Print comprehensive final statistics"""
        if not self.start_time:
            return
        
        total_time = time.time() - self.start_time
        fps = self.processed_frames / total_time if total_time > 0 else 0
        avg_inference = np.mean(self.inference_times) if self.inference_times else 0
        
        print(f"\n" + "="*70)
        print(f"üéØ NVDEC + TENSORRT PROCESSING COMPLETE")
        print(f"="*70)
        
        print(f"\nüìä Performance Summary:")
        print(f"   Frames processed: {self.processed_frames}")
        print(f"   Total time: {total_time/60:.1f} minutes")
        print(f"   Processing speed: {fps:.1f} FPS")
        print(f"   Real-time multiplier: {fps/25:.1f}x")
        
        print(f"\n‚ö° Inference Metrics:")
        print(f"   Average inference: {avg_inference:.1f}ms per batch")
        if avg_inference > 0:
            print(f"   Throughput: {self.batch_size * 1000 / avg_inference:.1f} images/second")
        else:
            print(f"   Throughput: N/A (no inference data)")
        
        print(f"\nüêü Detection Results:")
        print(f"   Total detections: {self.total_detections}")
        if self.processed_frames > 0:
            print(f"   Detections per frame: {self.total_detections/self.processed_frames:.2f}")
        else:
            print(f"   Detections per frame: N/A (no frames processed)")
        
        # Performance assessment vs targets
        target_10x = 250  # 10x real-time for 25fps
        achievement = (fps / target_10x) * 100
        
        print(f"\nüéØ Performance vs Targets:")
        print(f"   10x real-time target: {achievement:.1f}%")
        if fps >= target_10x:
            print(f"   ‚úÖ TARGET ACHIEVED! ({fps:.1f} >= {target_10x} FPS)")
        else:
            print(f"   üü° Below target ({fps:.1f} < {target_10x} FPS)")


def main():
    parser = argparse.ArgumentParser(description='NVDEC Production Video Processing')
    parser.add_argument('video_path', help='Path to input video file')
    parser.add_argument('--output', help='Output CSV file (auto-generated if not specified)')
    parser.add_argument('--engine', default='models/auklab_model_xlarge_combined_4564_v1_clean.trt', 
                       help='TensorRT engine path')
    parser.add_argument('--batch-size', type=int, default=16, 
                       help='Batch size for processing')
    parser.add_argument('--frame-skip', type=int, default=25, 
                       help='Process every Nth frame')
    parser.add_argument('--max-frames', type=int, help='Maximum frames to process (for testing)')
    
    args = parser.parse_args()
    
    # Validate inputs
    if not os.path.exists(args.video_path):
        print(f"‚ùå Video file not found: {args.video_path}")
        return 1
    
    if not os.path.exists(args.engine):
        print(f"‚ùå TensorRT engine not found: {args.engine}")
        return 1
    
    # Generate output filename if not specified
    if not args.output:
        video_stem = Path(args.video_path).stem
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        args.output = f"nvdec_results_{video_stem}_{timestamp}.csv"
    
    print(f"üé¨ NVDEC Production Video Processing")
    print(f"   Input: {args.video_path}")
    print(f"   Engine: {args.engine}")
    print(f"   Output: {args.output}")
    print(f"   Batch size: {args.batch_size}")
    print(f"   Frame skip: {args.frame_skip}")
    
    try:
        # Create processor and run
        processor = NVDECTensorRTProcessor(args.engine, args.batch_size)
        results = processor.process_video_nvdec(
            video_path=args.video_path,
            output_csv=args.output,
            frame_skip=args.frame_skip,
            max_frames=args.max_frames
        )
        
        print(f"\n‚úÖ Processing complete! Results saved to: {args.output}")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå Processing failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())